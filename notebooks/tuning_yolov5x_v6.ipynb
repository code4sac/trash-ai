{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# yolov5x6 trained for 300 epochs."
      ],
      "metadata": {
        "id": "RJQb7ylX2vHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "0D7J191IYwp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e409ed-ce47-42cc-9bb1-95f5571a546c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 18 21:42:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ultralytics/yolov5 \n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt wandb"
      ],
      "metadata": {
        "id": "2TTOdqkAk_Ad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FBHHieZsCbGS"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ExifTags\n",
        "from pycocotools.coco import COCO\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from matplotlib.collections import PatchCollection\n",
        "import colorsys\n",
        "import random\n",
        "import pylab\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from tqdm import tqdm\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UMKb-KDK3kta"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd ..\n",
        "!gdown 1X3O2v3GIPveq3ylWF6o1qHI5uzbN1vWA\n",
        "!unzip rotated2.zip\n",
        "%mv /content/content/* /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YFKQFNzuKOBI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# dataset_path = './data'\n",
        "# anns_file_path = dataset_path + '/' + 'annotations.json'\n",
        "\n",
        "# # Read annotations\n",
        "# with open(anns_file_path, 'r') as f:\n",
        "#     dataset = json.loads(f.read())\n",
        "\n",
        "# categories = dataset['categories']\n",
        "# anns = dataset['annotations']\n",
        "# imgs = dataset['images']\n",
        "# nr_cats = len(categories)\n",
        "# nr_annotations = len(anns)\n",
        "# nr_images = len(imgs)\n",
        "\n",
        "# # Load categories and super categories\n",
        "# cat_names = []\n",
        "# super_cat_names = []\n",
        "# super_cat_ids = {}\n",
        "# super_cat_last_name = ''\n",
        "# nr_super_cats = 0\n",
        "# for cat_it in categories:\n",
        "#     cat_names.append(cat_it['name'])\n",
        "#     super_cat_name = cat_it['supercategory']\n",
        "#     # Adding new supercat\n",
        "#     if super_cat_name != super_cat_last_name:\n",
        "#         super_cat_names.append(super_cat_name)\n",
        "#         super_cat_ids[super_cat_name] = nr_super_cats\n",
        "#         super_cat_last_name = super_cat_name\n",
        "#         nr_super_cats += 1\n",
        "\n",
        "# print('Number of super categories:', nr_super_cats)\n",
        "# print('Number of categories:', nr_cats)\n",
        "# print('Number of annotations:', nr_annotations)\n",
        "# print('Number of images:', nr_images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Read annotations\n",
        "# dataset_path = './data'\n",
        "# anns_file_path = dataset_path + '/' + 'annotations.json'\n",
        "\n",
        "# with open(anns_file_path, 'r') as f:\n",
        "#     dataset = json.loads(f.read())\n",
        "# imgs = dataset['images']\n",
        "\n",
        "# data_source = COCO(annotation_file=anns_file_path)"
      ],
      "metadata": {
        "id": "Wv0pxzxSnA-l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzhrp4RiHKiW",
        "outputId": "def69957-dcf8-466c-e1a2-88f66e3afa2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train test split\n",
        "'''\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "'''\n",
        "import random\n",
        "id_list=[i for i in range(1500)]\n",
        "random.shuffle(id_list)\n",
        "\n",
        "train_ids = id_list[:1050]\n",
        "val_ids = id_list[1050:1050+300]\n",
        "test_ids = id_list[1050+300:]\n",
        "\n",
        "def move_helper(ids, desti):\n",
        "  for id in ids:\n",
        "    img_name = os.path.join( './yoloTACO/images', str(id)+'.jpg' )\n",
        "    lbl_name = os.path.join( './yoloTACO/labels', str(id)+'.txt' )\n",
        "    print(img_name)\n",
        "    if os.path.isfile(img_name):\n",
        "        shutil.move( img_name, 'yoloTACO/images/'+desti)\n",
        "        shutil.move( lbl_name, 'yoloTACO/labels/'+desti)\n",
        "    else :\n",
        "        print('file does not exist', img_name)"
      ],
      "metadata": {
        "id": "CPFCzX31IGBq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!mkdir yoloTACO/images/train\n",
        "!mkdir yoloTACO/images/val\n",
        "!mkdir yoloTACO/images/test\n",
        "!mkdir yoloTACO/labels/train\n",
        "!mkdir yoloTACO/labels/val\n",
        "!mkdir yoloTACO/labels/test\n",
        "move_helper(test_ids,'test')\n",
        "move_helper(train_ids,'train')\n",
        "move_helper(val_ids,'val')"
      ],
      "metadata": {
        "id": "kwCWClsrSD4z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title yml\n",
        "\n",
        "with open('/content/yolov5/data/yoloTACO.yaml', mode='w') as fp:\n",
        "  lines = '''path: ../yoloTACO  # dataset root dir\n",
        "train: images/train  # train images (relative to 'path') 128 images\n",
        "val: images/val  # val images (relative to 'path') 128 images\n",
        "test: images/test # test images (optional)\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: Aluminium foil\n",
        "  1: Battery\n",
        "  2: Aluminium blister pack\n",
        "  3: Carded blister pack\n",
        "  4: Other plastic bottle\n",
        "  5: Clear plastic bottle\n",
        "  6: Glass bottle\n",
        "  7: Plastic bottle cap\n",
        "  8: Metal bottle cap\n",
        "  9: Broken glass\n",
        "  10: Food Can\n",
        "  11: Aerosol\n",
        "  12: Drink can\n",
        "  13: Toilet tube\n",
        "  14: Other carton\n",
        "  15: Egg carton\n",
        "  16: Drink carton\n",
        "  17: Corrugated carton\n",
        "  18: Meal carton\n",
        "  19: Pizza box\n",
        "  20: Paper cup\n",
        "  21: Disposable plastic cup\n",
        "  22: Foam cup\n",
        "  23: Glass cup\n",
        "  24: Other plastic cup\n",
        "  25: Food waste\n",
        "  26: Glass jar\n",
        "  27: Plastic lid\n",
        "  28: Metal lid\n",
        "  29: Other plastic\n",
        "  30: Magazine paper\n",
        "  31: Tissues\n",
        "  32: Wrapping paper\n",
        "  33: Normal paper\n",
        "  34: Paper bag\n",
        "  35: Plastified paper bag\n",
        "  36: Plastic film\n",
        "  37: Six pack rings\n",
        "  38: Garbage bag\n",
        "  39: Other plastic wrapper\n",
        "  40: Single-use carrier bag\n",
        "  41: Polypropylene bag\n",
        "  42: Crisp packet\n",
        "  43: Spread tub\n",
        "  44: Tupperware\n",
        "  45: Disposable food container\n",
        "  46: Foam food container\n",
        "  47: Other plastic container\n",
        "  48: Plastic glooves\n",
        "  49: Plastic utensils\n",
        "  50: Pop tab\n",
        "  51: Rope & strings\n",
        "  52: Scrap metal\n",
        "  53: Shoe\n",
        "  54: Squeezable tube\n",
        "  55: Plastic straw\n",
        "  56: Paper straw\n",
        "  57: Styrofoam piece\n",
        "  58: Unlabeled litter\n",
        "  59: Cigarette'''\n",
        "  fp.writelines(lines)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "evH7jgs5Dnj7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./yolov5\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMrwEgnB9C4",
        "outputId": "a21994eb-e1cd-4127-bb71-8320b6099ea3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "benchmarks.py\t detect.py   models\t       setup.cfg       val.py\n",
            "classify\t export.py   README.md\t       train.py\n",
            "CONTRIBUTING.md  hubconf.py  requirements.txt  tutorial.ipynb\n",
            "data\t\t LICENSE     segment\t       utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if we have\n",
        "!pip list -v | grep [Aa]lbumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fo3QB_POP2w",
        "outputId": "cc8b25f1-58fb-4605-c6b3-ac882ddfeb27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "albumentations                1.2.1                        /usr/local/lib/python3.7/dist-packages pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --img 1280 \\\n",
        " --batch-size 4 --epochs 300 \\\n",
        " --data yoloTACO.yaml \\\n",
        " --weights yolov5x6.pt \\\n",
        "# --multi-scale \\\n",
        "# --freeze 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KP4-17g9UwZ",
        "outputId": "8b333cb3-fb3a-4c11-e39a-c85e05da3eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x6.pt, cfg=, data=yoloTACO.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=4, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.2-137-gfda8aa5 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs in Weights & Biases\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 49.9MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x6.pt to yolov5x6.pt...\n",
            "100% 270M/270M [00:08<00:00, 32.7MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=60\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   5531520  models.common.Conv                      [640, 960, 3, 2]              \n",
            "  8                -1  4  11070720  models.common.C3                        [960, 960, 4]                 \n",
            "  9                -1  1  11061760  models.common.Conv                      [960, 1280, 3, 2]             \n",
            " 10                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            " 11                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 12                -1  1   1230720  models.common.Conv                      [1280, 960, 1, 1]             \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  4  11992320  models.common.C3                        [1920, 960, 4, False]         \n",
            " 16                -1  1    615680  models.common.Conv                      [960, 640, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 20                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 24                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 27                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  4  11377920  models.common.C3                        [1280, 960, 4, False]         \n",
            " 30                -1  1   8296320  models.common.Conv                      [960, 960, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  4  20495360  models.common.C3                        [1920, 1280, 4, False]        \n",
            " 33  [23, 26, 29, 32]  1    624780  models.yolo.Detect                      [60, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [320, 640, 960, 1280]]\n",
            "Model summary: 575 layers, 140602540 parameters, 140602540 gradients, 210.0 GFLOPs\n",
            "\n",
            "Transferred 955/963 items from yolov5x6.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 159 weight(decay=0.0), 163 weight(decay=0.0005), 163 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yoloTACO/labels/train' images and labels...1050 found, 0 missing, 1 empty, 0 corrupt: 100% 1050/1050 [00:00<00:00, 4549.88it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yoloTACO/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yoloTACO/labels/val' images and labels...300 found, 0 missing, 0 empty, 0 corrupt: 100% 300/300 [00:00<00:00, 2268.12it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yoloTACO/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.91 anchors/target, 0.979 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 1 of 3286 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 3286 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7385: 100% 1000/1000 [00:08<00:00, 118.68it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9991 best possible recall, 5.60 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=1280, metric_all=0.290/0.739-mean/best, past_thr=0.491-mean: 14,12, 23,22, 41,40, 82,58, 71,91, 116,119, 188,99, 173,176, 254,255, 401,348, 255,643, 653,528\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/299      14.5G    0.08877    0.05172    0.09766         27       1280:  85% 224/263 [02:14<00:25,  1.55it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.plots import plot_results \n",
        "plot_results('/content/yolov5/runs/train/exp/results.csv') "
      ],
      "metadata": {
        "id": "NWU7yiRACz95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.Image(\"./runs/train/exp/results.png\")"
      ],
      "metadata": {
        "id": "vEY3GiSUD_qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --data yoloTACO.yaml --weights runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "id": "DoLh0BGlXQMC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}